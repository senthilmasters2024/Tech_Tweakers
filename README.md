# Tech_Tweakers
ML 24/25-09 Semantic Similarity Analysis of Textual Data
**Project Requirement:**
In this project, students must leverage OpenAI's GPT to create embeddings for a set of documents. The solution should utilize the OpenAI NuGet package, as demonstrated in this example: OpenAI Samples.
The primary objective of this project is to explore and quantify the semantic similarity between various levels of textual data, including words, phrases, sentences, paragraphs, and entire documents. The analysis will focus on measuring and comparing semantic relationships, leveraging examples with well-known entities and terms to highlight key insights.
Key Objectives:
1.	Word and Phrase Similarity Analysis:
o	Investigate semantic relationships between pairs of phrases, such as:
	“Angela Merkel” vs. “Government”
	“Cristiano Ronaldo” vs. “Government”
o	Highlight the variance in similarity across different domains and contexts.
2.	Document-Level Comparisons:
o	Analyze semantic similarity between documents on the same topic and those on unrelated topics.
o	Provide insights into how contextual alignment impacts semantic similarity.
3.	Demonstration and Validation:
o	Use examples involving widely recognized names, phrases, and documents to illustrate findings clearly and effectively.
o	Showcase the versatility of semantic similarity metrics across diverse scenarios.
Deliverables:
1.	Data Visualization:
o	Generate CSV files containing similarity metrics to facilitate the creation of diagrams using external tools like Microsoft Excel or Tableau.
o	Provide illustrative diagrams to validate and support the results of the analysis.
2.	Reproducible Codebase:
o	Develop a robust codebase that computes semantic similarity scores.
o	Ensure the code is well-documented and capable of exporting results in CSV format for further processing.
3.	Methodology Documentation:
o	Clearly document the methods and algorithms used for semantic similarity computation.
o	Explain the choice of metrics (e.g., cosine similarity, embeddings) and any pre-trained models or algorithms applied (e.g., Word2Vec, BERT).
