Semantic Similarity Analysis of Textual Data
This project performs semantic analysis of textual data using .NET and C# in Visual Studio. The system processes text inputs at three levels: word, phrase, and document. Inputs are stored in designated folders and fetched for processing. The analysis is based on cosine similarity to measure text similarity.

a) Technology Stack

Programming Language: C#

Development Environment: Visual Studio

Framework: .NET Core/.NET Framework

Libraries:

System.IO for file handling

ML.NET or custom implementations for cosine similarity

Other NLP libraries if required

b)Processing Steps are as follows:

Data Fetching: The program scans the designated folder and reads text files.

Preprocessing:

Tokenization

Stopword removal (if necessary)

Normalization

Feature Extraction:

Vectorization of text using TF-IDF

Cosine Similarity Computation:

Converts text into vector space

Computes similarity scores between input texts

Output Generation:

Stores results in a structured format (e.g., JSON, CSV, or database)

c) Cosine Similarity Calculation is performed on the following basis:

Cosine similarity is used to measure the similarity between text vectors:

d(A, B) = (A • B) / (||A|| ||B||)

Where:

A and B are text vectors

A • B represents the dot product of the vectors

||A|| and ||B|| are the magnitudes of the vectors

Based on the researches, the following steps has been decided to follow to implement the task succesfully:

1) Apply the input (word, text or documents) into a preprocessing section. 
2) The output from the preprocessor is successfully applied to a section to create Embeddings using OpenAi's GPT model. 
3) From the high dimensional vector space, using a similarity model, the 'Semantic Similarity' will be extracted.
4) For Visualization part, we need to generate CSV file and then can generate Heatmaps or Network Graphs for understanding.

It is also founded that GPT doesnot provide numerical representation directly unlike other models including Sentence-BERT. Also , the Embeddings can be word or Sentence Embedding depending on the context. OpenAI also provides  endpoint (/v1/embeddings) for obtaining embeddings directly, this is quite efficient than GPTs completion endpoint.

The following are some of the easily available OpenAI's models used by GPT to generate vector space:

 .     text-similarity-ada-001
•	text-similarity-babbage-002
•	text-similarity-curie-001
•	text-similarity-davinci-002


Here, the  text-similarity-ada-001 is the popular one among others due to its simplicity and speed. The text-similarity-babbage-002 model is expensive than "ada models" . Its is preferred over "ada" for those tasks demanding a reasonable balance with less computationally such as keyword matching, basic semantic similarity analysis. The text-similarity-curie-001model is the one with better accuracy and performance as well as costly compared to ada. The model text-similarity-davinci-002 is the most advanced and hence the expensive. It can be integrated with, for applications which needs the highest precision with the ability to understand complex contextual relationships.  
 
As mentioned once the vector space is obtained by Embeddings, we can extract the similarity by using the below metric models: 
Cosine similarity is the measure of similarity between two non-zero vectors widely applied in many machine learning and data analysis applications. It actually measures the cosine of the angle between two vectors. As a result, an idea is given about how far the two vectors point in the same direction irrespective of their magnitudes. It can be found in popular usage in tasks of text analysis, such as comparison of similarity between documents, search queries, and even recommendation systems so that user preferences can be matched.

Similarity measure refers to distance with dimensions representing features of the data object, in a dataset. If this distance is less, there will be a high degree of similarity, but when the distance is large, there will be a low degree of similarity. Some of the popular similarity measures are given below:

Euclidean Distance
Manhattan Distance
Jaccard Similarity
Minkowski Distance
Cosine Similarity
What is Cosine Similarity?
Cosine similarity is a metric, helpful in determining, how similar the data objects are irrespective of their size. We can measure the similarity between two sentences in Python using Cosine Similarity. In cosine similarity, data objects in a dataset are treated as a vector. The formula to find the cosine similarity between two vectors is –

S
C
S 
C
​
 (x, y) = x . y / ||x|| 
×
× ||y||
where,

x . y = product (dot) of the vectors ‘x’ and ‘y’.
||x|| and ||y|| = length (magnitude) of the two vectors ‘x’ and ‘y’.
||x|| 
×
× ||y|| = regular product of the two vectors ‘x’ and ‘y’.
Example
Consider an example to find the similarity between two vectors – ‘x’ and ‘y’, using Cosine Similarity. The ‘x’ vector has values, x = { 3, 2, 0, 5 } The ‘y’ vector has values, y = { 1, 0, 0, 0 } The formula for calculating the cosine similarity is : 
S
C
S 
C
​
 (x, y) = x . y / ||x|| 
×
× ||y||

x . y = 3*1 + 2*0 + 0*0 + 5*0 = 3

||x|| = √ (3)^2 + (2)^2 + (0)^2 + (5)^2 = 6.16

||y|| = √ (1)^2 + (0)^2 + (0)^2 + (0)^2 = 1

∴ 
S
C
S 
C
​
 (x, y) = 3 / (6.16 * 1) = 0.49 

 (x, y) = 1 - 0.49 = 0.51
The cosine similarity between two vectors is measured in ‘θ’.
If θ = 0°, the ‘x’ and ‘y’ vectors overlap, thus proving they are similar.
If θ = 90°, the ‘x’ and ‘y’ vectors are dissimilar.

Of these above mentioned similarity metric models, the Cosine and Euclidean methods are the widely followed and easily adapted one due to less computational complexity.

Reference:
https://www.geeksforgeeks.org/cosine-similarity/



